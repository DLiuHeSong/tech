ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ•™å­¦é¡¹ç›®ç»“æ„ï¼ŒåŸºäº **LangChain + LlamaIndex** å®ç°ç§æœ‰æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œé€‚åˆç”¨äºæ•™å­¦æˆ–å¼€å‘åŸå‹ç³»ç»Ÿã€‚

---

# ğŸ§± æ•™å­¦é¡¹ç›®ç»“æ„ï¼šLangChain + LlamaIndex æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

```
llama_langchain_demo/
â”œâ”€â”€ main.py                        # ä¸»è¿è¡Œå…¥å£
â”œâ”€â”€ requirements.txt              # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ config.py                     # é…ç½®é¡¹ï¼ˆAPI Keyç­‰ï¼‰
â”œâ”€â”€ data/
â”‚   â””â”€â”€ example.txt               # ç¤ºä¾‹æ–‡æ¡£ï¼ˆå¯è‡ªè¡Œæ·»åŠ ï¼‰
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ llm_init.py               # LLM åˆå§‹åŒ–æ¨¡å—
â”‚   â””â”€â”€ index_builder.py          # æ„å»ºç´¢å¼•æ¨¡å—
â”‚   â””â”€â”€ query_engine.py           # æŸ¥è¯¢å¼•æ“å°è£…
â””â”€â”€ README.md                     # æ•™å­¦è¯´æ˜æ–‡æ¡£
```

---

## ğŸ“„ ç¤ºä¾‹æ–‡æ¡£å†…å®¹ï¼ˆ`data/example.txt`ï¼‰

```text
LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨çš„å¼€å‘æ¡†æ¶ã€‚LlamaIndex æ˜¯ä¸€ä¸ªç”¨äºå°†ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®è¿æ¥åˆ°è¯­è¨€æ¨¡å‹çš„å·¥å…·ã€‚
```

---

## ğŸ§ª ç¤ºä¾‹è¿è¡Œæµç¨‹ï¼ˆ`main.py`ï¼‰

```python
# main.py
from utils.llm_init import init_llm
from utils.index_builder import build_index
from utils.query_engine import create_engine

if __name__ == "__main__":
    llm = init_llm()
    index = build_index("data/")
    query_engine = create_engine(index, llm)

    while True:
        query = input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰ï¼š")
        if query.strip().lower() == "exit":
            break
        response = query_engine.query(query)
        print("ğŸ¤– ç­”æ¡ˆï¼š", response)
```

---

## ğŸ§° æ¨¡å—è¯¦è§£

### ğŸ”§ `utils/llm_init.py`

```python
from langchain.chat_models import ChatOpenAI
import os

def init_llm():
    return ChatOpenAI(
        temperature=0,
        model_name="gpt-3.5-turbo",
        openai_api_key=os.environ["OPENAI_API_KEY"]
    )
```

### ğŸ”§ `utils/index_builder.py`

```python
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex

def build_index(doc_dir: str):
    documents = SimpleDirectoryReader(doc_dir).load_data()
    return VectorStoreIndex.from_documents(documents)
```

### ğŸ”§ `utils/query_engine.py`

```python
from llama_index.core.query_engine import RetrieverQueryEngine

def create_engine(index, llm):
    return index.as_query_engine(llm=llm)
```

---

## ğŸ“¦ requirements.txt

```txt
openai
langchain
llama-index
```

å®‰è£…æ–¹å¼ï¼š

```bash
pip install -r requirements.txt
```

---

## ğŸ“˜ README.md ç¤ºä¾‹å†…å®¹

````markdown
# LangChain + LlamaIndex æ•™å­¦é¡¹ç›®

## ğŸ§  é¡¹ç›®ç›®æ ‡
æ„å»ºä¸€ä¸ªç§æœ‰æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æé—®ï¼Œè‡ªåŠ¨ä»æœ¬åœ°æ–‡æ¡£ä¸­æ£€ç´¢ç­”æ¡ˆã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„
- `data/`ï¼šæ”¾ç½®éœ€è¦æ£€ç´¢çš„æ–‡æœ¬æ–‡ä»¶
- `utils/`ï¼šå°è£… LLM åˆå§‹åŒ–ã€ç´¢å¼•æ„å»ºã€æŸ¥è¯¢å¼•æ“ç­‰æ¨¡å—
- `main.py`ï¼šäº¤äº’å¼é—®ç­”å…¥å£

## ğŸš€ è¿è¡Œæ–¹å¼
1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export OPENAI_API_KEY=ä½ çš„key
````

2. å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

3. å¯åŠ¨é—®ç­”ç³»ç»Ÿï¼š

```bash
python main.py
```

## ğŸ§ª ç¤ºä¾‹é—®é¢˜

* LangChain æ˜¯ä»€ä¹ˆï¼Ÿ
* LlamaIndex çš„ä½œç”¨ï¼Ÿ


---
## ğŸ“¦ å¯é€‰å¢å¼ºæ¨¡å—ï¼ˆæ‹“å±•ç»ƒä¹ ï¼‰

| æ¨¡å—         | è¯´æ˜                                  |
|--------------|---------------------------------------|
| PDFLoader     | æ”¯æŒåŠ è½½ PDF æ–‡æ¡£                     |
| å¤šè½®å¯¹è¯è®°å¿†  | åŠ å…¥ LangChain çš„ Memory æ¨¡å—          |
| Web æ¥å£      | ä½¿ç”¨ Flask/FastAPI æä¾› API æœåŠ¡        |
| å‘é‡å­˜å‚¨æŒä¹…åŒ– | æ”¯æŒ FAISS / Weaviate ç­‰ä¿å­˜ç´¢å¼•       |
| Agent æ¨¡å¼    | åŠ å…¥æœç´¢å·¥å…·ã€å‡½æ•°è°ƒç”¨ç­‰å¤æ‚åœºæ™¯       |

---



