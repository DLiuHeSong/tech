# 简历语义分析与向量技术详解

---

## 第一章：向量是什么？现实中存在吗？

### 1.1 向量的直观概念

* 向量在几何中是表示方向与大小的量（如：二维坐标点 `[x, y]`，三维空间 `[x, y, z]`）。
* 语言模型中的向量是高维空间中的数学表示，常用于表示语义特征。

### 1.2 高维向量的本质（如 1536 或 2048维）

* 并不对应现实中能“画出”的空间，而是模型训练过程中自动学习出的语义因子。
* 比如某个维度可能反映“技术性强弱”，另一个维度反映“表达正式度”。
* 维度越多，表示能力越强（但也会带来计算开销）。

### 1.3 为什么文本能变成向量？

* 通过 embedding 模型（如 `text-embedding-3-small`），一整段文本被转换为一个固定长度的浮点数数组。
* 示例：

```json
输入文本："熟悉 Java 开发，有推荐系统经验"
输出向量：[-0.005, 0.013, ..., 0.006]（共1536个float值）
```

---

## 第二章：向量是如何生成与使用的？

### 2.1 生成流程

* 使用 OpenAI API 或开源 embedding 模型（如 bge-small-zh）
* 输入：任意自然语言文本
* 输出：高维向量数组（float32 列表）

### 2.2 是“每个字”还是“整段话”？

* ✅ 是对“整段文本”做 embedding
* ❌ 并不是每个字一个向量
* 模型会综合整段的语义表示出向量

### 2.3 相似度怎么计算？（余弦相似度）

* 用两个向量的夹角计算语义相似性：

```
cos_sim(A, B) = (A • B) / (||A|| * ||B||)
```

* A•B 是点积，||A|| 是 A 的模（平方和开根号）
* 值域为 \[-1, 1]，越接近 1 越相似

### 2.4 示例

```python
from numpy import dot
from numpy.linalg import norm

def cosine_similarity(a, b):
    return dot(a, b) / (norm(a) * norm(b))
```

---

## 第三章：LangChain 与 LlamaIndex 的定位和区别

### 3.1 LlamaIndex 是什么？

* 原名 GPT Index，用于\*\*文档向量索引 + 检索增强生成（RAG）\*\*的工具。
* 功能包括：

  * 多格式文档加载（PDF、DOCX、图片 OCR）
  * 文本切分成 chunk
  * 向量 embedding 构建
  * 检索匹配后喂给 GPT

### 3.2 LangChain 是什么？

* 构建复杂 LLM 工作流的框架。
* 适合：多步骤 Agent、工具链调用、插件式流程（如 Google Search、SQL 查询、代码执行）

### 3.3 两者区别

| 项目     | LlamaIndex  | LangChain    |
| ------ | ----------- | ------------ |
| 主要用途   | 文档问答系统（RAG） | LLM 应用工作流编排  |
| 是否专注检索 | 是           | 否（需手动接入向量搜索） |
| 支持向量索引 | 内置          | 通常需要集成其他库    |
| 是否轻量   | 是           | 偏重，适合复杂应用    |

---

## 第四章：增强版简历分析系统设计（结合 OpenAI + LlamaIndex）

### 4.1 目标

* 用户上传多份简历（PDF/DOCX/图片）
* 支持自然语言提问
* 系统自动识别相关段落 → 回溯原始简历 → GPT 综合分析输出答案

### 4.2 原始问题与解决思路

| 问题         | 描述                     | 解决方式                             |
| ---------- | ---------------------- | -------------------------------- |
| 信息片段太碎     | 检索结果是片段，缺失人名等关键信息      | 给每个 chunk 添加 metadata（如文件名 = 人名） |
| GPT 无法判断身份 | chunk 只有“我会Java”，上下文丢失 | 用向量命中的文件名加载全文重新问 GPT             |
| GPT 上下文缺失  | 只问“谁会 Java”时可能漏人       | 加 prompt 说明，让 GPT 推理 + 汇总分析      |

### 4.3 系统架构流程

```text
用户提问
 ↓
对问题向量化 → 检索向量库（Top-K 匹配段）
 ↓
获取匹配段的所属文件名（metadata）
 ↓
加载完整原始简历文本
 ↓
构造 Prompt：问题 + 原始简历
 ↓
传入 GPT → 输出判断结果
```

### 4.4 DEMO 示例功能点

* 每个 chunk 嵌入时附加原文定位信息（metadata：文件名、页码、起始位置）
* 检索阶段保留 ID，用于快速索引原始文档
* GPT Prompt 构造方式：

```
你是一位HR，请根据以下简历判断：问题是「谁会Java」
以下是张三的简历：...
请总结其是否满足该条件，以及理由。
```

---

## 第五章：优化点与拓展建议

### 5.1 为避免信息缺失：建议做“二阶段”处理

* 第一阶段：向量召回片段 + 抽出身份ID
* 第二阶段：加载原文 → 问 GPT

### 5.2 性能优化

* Top-K 精调（如先召回20段，再筛选文件）
* 支持 ID 映射缓存、embedding 批量向量化
* 使用更小的模型（如 bge-base）本地部署

### 5.3 可视化建议

* 使用 PCA/t-SNE 降维，把简历语义分布做 2D 图（可看哪些人语义相近）
* 显示 Top-N 召回段 + 其来源文件名，增强透明度

### 5.4 后续功能扩展

* JD 与简历的双向匹配
* 多轮筛选条件组合问答
* 简历打分排序 & 推荐解释
* Web 可视化界面（Streamlit + charts）

---

## 附录：关键词整理

* **Embedding**：语义向量表示
* **Cosine Similarity**：余弦相似度计算
* **RAG**：检索增强生成
* **Chunking**：文档分段
* **Metadata 回溯机制**：embedding 命中后找回原始上下文
* **向量数据库**：Faiss, Qdrant, Chroma
* **Prompt 设计**：带上下文的智能提问技巧
* **语义压缩与表达**：高维语义空间理解

---
---

#### [`下一章` 1.1 向量是什么？现实中存在吗？](/AI/knowledge_base/1.2-langchain_llama.md)
